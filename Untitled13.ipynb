{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 유튜브 댓글 수집"
      ],
      "metadata": {
        "id": "p9RJXKsGjOkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**youtube-comment-downloader 다운**"
      ],
      "metadata": {
        "id": "pbywdt-OjUua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qINaaYuOi-5m"
      },
      "outputs": [],
      "source": [
        "!pip install youtube-comment-downloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈 불러오기\n",
        "import os         # 운영체제 명령어 실행 및 파일 삭제 등에 사용\n",
        "import json       # JSON 파일을 읽기 위해 사용\n",
        "import pandas as pd  # 데이터프레임 사용을 위해 pandas 불러옴\n",
        "\n",
        "# 사용자에게 유튜브 영상 URL을 입력받음\n",
        "url = input(\"유튜브 영상 링크를 입력하세요: \").strip()  # strip()은 앞뒤 공백 제거\n",
        "\n",
        "# 댓글 데이터를 저장할 JSON 파일 이름\n",
        "json_file = 'YoutubeComments.json'\n",
        "\n",
        "# 최종적으로 저장할 CSV 파일 이름\n",
        "csv_file = 'YoutubeComments.csv'\n",
        "\n",
        "# 터미널 명령어를 통해 youtube-comment-downloader 실행\n",
        "# 입력한 URL에서 댓글을 추출해서 json_file 이름으로 저장함\n",
        "# ※사전에 !pip install youtube-comment-downloader해서 youtube-comment-downloader를 다운 받아둬야 함\n",
        "os.system(f'youtube-comment-downloader --url \"{url}\" --output {json_file}')\n",
        "\n",
        "# 저장된 JSON 파일을 읽음\n",
        "# 각 줄(line)은 하나의 JSON 객체이므로 이를 파싱해서 리스트로 저장\n",
        "with open(json_file, 'r', encoding='utf-8') as f:\n",
        "    json_data = [json.loads(line) for line in f]  # 줄마다 json.loads로 파싱\n",
        "\n",
        "# JSON 데이터를 pandas DataFrame으로 변환\n",
        "# 구조화된 테이블 형태로 가공\n",
        "df = pd.DataFrame(json_data)\n",
        "\n",
        "# DataFrame을 CSV 파일로 저장\n",
        "# index=False는 인덱스 열을 저장하지 않음\n",
        "# encoding='utf-8-sig'는 엑셀에서 한글이 깨지는 것을 방지하기 위한 설정\n",
        "df.to_csv(csv_file, index=False, encoding='utf-8-sig')\n",
        "\n",
        "# JSON 임시 파일 삭제 (필요 없으므로 정리)\n",
        "os.remove(json_file)\n",
        "\n",
        "# 사용자에게 완료 메시지를 출력\n",
        "print(f\"\\n댓글이 {csv_file} 파일로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "VRppLkZYjB2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 언어 감지 코드"
      ],
      "metadata": {
        "id": "JUOBMQ1vjZfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**langid 모델 설치**"
      ],
      "metadata": {
        "id": "gNzDmGU5jdby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langid"
      ],
      "metadata": {
        "id": "LQNXV8v0jJBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd      # 데이터프레임을 다루기 위한 pandas\n",
        "import langid            # 텍스트의 언어를 자동으로 판별해주는 라이브러리\n",
        "import re                # 정규표현식 처리용 라이브러리\n",
        "\n",
        "# 처리할 CSV 파일 경로 (Colab에 업로드한 유튜브 댓글 파일)\n",
        "file_path = 'YoutubeComments.csv'\n",
        "\n",
        "# CSV 파일을 pandas로 불러와서 DataFrame으로 저장\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 1. 한국어 초성 및 인터넷 은어(줄임말, 신조어)를 감지하는 함수\n",
        "def is_korean_internet_slang(text):\n",
        "    if pd.isna(text):     # 결측값(NaN)이면 False 반환\n",
        "        return False\n",
        "    text = str(text).strip()  # 문자열로 변환하고 양쪽 공백 제거\n",
        "\n",
        "    return (\n",
        "        # 초성(ㄱ~ㅎ), 모음(ㅏ~ㅣ), ㅋ, ㅎ 만 반복된 문자열 (ex: ㅋㅋ, ㅜㅠ, ㅎㅅㅎ)\n",
        "        bool(re.fullmatch(r'[ㄱ-ㅎㅏ-ㅣㅜㅠㅋㅎ\\s]+', text)) or\n",
        "        # 많이 쓰이는 은어 일부를 직접 포함 여부로 판별\n",
        "        'ㄹㅇ' in text or   # \"real\", 진짜라는 의미\n",
        "        'ㅇㅈ' in text or   # \"인정\"의 초성\n",
        "        'ㅅㅂ' in text or   # 욕설 초성\n",
        "        'ㅋㅋㅋ' in text or # 웃음 표현\n",
        "        'ㄷㄷ' in text      # \"덜덜\", 놀람 표현\n",
        "    )\n",
        "\n",
        "# 2. 텍스트를 정리하는 함수 (특수문자 제거)\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):     # 결측값이면 빈 문자열 반환\n",
        "        return ''\n",
        "    # 한글, 영어, 숫자, 공백 외 모든 특수문자 제거\n",
        "    return re.sub(r'[^\\w\\sㄱ-힣]', '', str(text))\n",
        "\n",
        "# 3. 언어 감지 함수 (langid 사용 + 한글 은어 직접 처리 포함)\n",
        "def detect_langid_custom(text):\n",
        "    try:\n",
        "        text = str(text).strip()  # 문자열로 변환하고 공백 제거\n",
        "        if len(text) < 2:\n",
        "            return 'unknown'     # 너무 짧은 글은 판별 불가능\n",
        "        if is_korean_internet_slang(text):\n",
        "            return 'ko'          # 초성이나 은어로 판별되면 한국어로 처리\n",
        "        cleaned = clean_text(text)  # 전처리\n",
        "        lang, _ = langid.classify(cleaned)  # langid로 언어 분류\n",
        "        return lang\n",
        "    except:\n",
        "        return 'unknown'  # 오류 발생 시 'unknown'으로 처리\n",
        "\n",
        "# 4. 실제로 각 댓글에 대해 언어를 분류하여 새로운 컬럼 'language'에 저장\n",
        "df['language'] = df['text'].apply(detect_langid_custom)\n",
        "\n",
        "# 5. 분류된 언어가 몇 개인지 종류별로 출력\n",
        "print(df['language'].value_counts())\n",
        "\n",
        "# 6. 결과를 새로운 CSV 파일로 저장\n",
        "df.to_csv('YoutubeComments_with_langid.csv', index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "fCV34EyjjNBa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}